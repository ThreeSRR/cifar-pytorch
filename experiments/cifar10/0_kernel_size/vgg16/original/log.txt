{'architecture': 'vgg16', 'data_path': './data', 'ckpt_path': './', 'ckpt_name': 'vgg16', 'num_classes': 10, 'dataset': 'cifar10', 'use_gpu': True, 'input_size': 32, 'epochs': 250, 'batch_size': 128, 'test_batch': 200, 'eval_freq': 2, 'workers': 4, 'optimize': {'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': True}, 'mixup': False, 'mixup_alpha': 0.4, 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True, 'cutout': False, 'holes': 1, 'length': 8}, 'lr_scheduler': {'type': 'STEP', 'base_lr': 0.1, 'lr_epochs': [100, 150, 200], 'lr_mults': 0.1, 'min_lr': 0.0, 'lower_bound': -6.0, 'upper_bound': 3.0}}
{'architecture': 'vgg16', 'data_path': './data', 'ckpt_path': './', 'ckpt_name': 'vgg16', 'num_classes': 10, 'dataset': 'cifar10', 'use_gpu': True, 'input_size': 32, 'epochs': 250, 'batch_size': 128, 'test_batch': 200, 'eval_freq': 2, 'workers': 4, 'optimize': {'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': True}, 'mixup': False, 'mixup_alpha': 0.4, 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True, 'cutout': False, 'holes': 1, 'length': 8}, 'lr_scheduler': {'type': 'STEP', 'base_lr': 0.1, 'lr_epochs': [100, 150, 200], 'lr_mults': 0.1, 'min_lr': 0.0, 'lower_bound': -6.0, 'upper_bound': 3.0}}
{'architecture': 'vgg16', 'data_path': './data', 'ckpt_path': './', 'ckpt_name': 'vgg16', 'num_classes': 10, 'dataset': 'cifar10', 'kernel_size': [5, 5, 3, 3, 3], 'use_gpu': True, 'input_size': 32, 'epochs': 250, 'batch_size': 128, 'test_batch': 200, 'eval_freq': 2, 'workers': 4, 'optimize': {'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': True}, 'mixup': False, 'mixup_alpha': 0.4, 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True, 'cutout': False, 'holes': 1, 'length': 8}, 'lr_scheduler': {'type': 'STEP', 'base_lr': 0.1, 'lr_epochs': [100, 150, 200], 'lr_mults': 0.1, 'min_lr': 0.0, 'lower_bound': -6.0, 'upper_bound': 3.0}}
{'architecture': 'vgg16', 'data_path': './data', 'ckpt_path': './', 'ckpt_name': 'vgg16', 'num_classes': 10, 'dataset': 'cifar10', 'kernel_size': [5, 5, 3, 3, 3], 'use_gpu': True, 'input_size': 32, 'epochs': 250, 'batch_size': 128, 'test_batch': 200, 'eval_freq': 2, 'workers': 4, 'optimize': {'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': True}, 'mixup': False, 'mixup_alpha': 0.4, 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True, 'cutout': False, 'holes': 1, 'length': 8}, 'lr_scheduler': {'type': 'STEP', 'base_lr': 0.1, 'lr_epochs': [100, 150, 200], 'lr_mults': 0.1, 'min_lr': 0.0, 'lower_bound': -6.0, 'upper_bound': 3.0}}
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Linear(in_features=512, out_features=10, bias=True)
)
 == total parameters: 15190090
            =======  Training  =======

 === Epoch: [1/250] === 
   == step: [100/391], train loss: 3.143 | train acc: 10.492% | lr: 0.100000
   == step: [200/391], train loss: 2.719 | train acc: 11.230% | lr: 0.100000
   == step: [300/391], train loss: 2.520 | train acc: 13.284% | lr: 0.100000
   == step: [391/391], train loss: 2.402 | train acc: 14.702% | lr: 0.100000
   == cost time: 48.0999s
 === Validate ===
   == test loss: 2.218 | test acc: 16.150%
 === Epoch: [2/250] === 
   == step: [100/391], train loss: 1.966 | train acc: 20.031% | lr: 0.100000
   == step: [200/391], train loss: 1.964 | train acc: 20.242% | lr: 0.100000
   == step: [300/391], train loss: 1.955 | train acc: 20.641% | lr: 0.100000
   == step: [391/391], train loss: 1.954 | train acc: 20.604% | lr: 0.100000
   == cost time: 41.5181s
 === Validate ===
   == test loss: 2.125 | test acc: 15.060%
 === Epoch: [3/250] === 
   == step: [100/391], train loss: 1.945 | train acc: 20.961% | lr: 0.100000
   == step: [200/391], train loss: 1.939 | train acc: 21.375% | lr: 0.100000
   == step: [300/391], train loss: 1.930 | train acc: 21.750% | lr: 0.100000
   == step: [391/391], train loss: 1.930 | train acc: 21.628% | lr: 0.100000
   == cost time: 41.6879s
 === Epoch: [4/250] === 
   == step: [100/391], train loss: 1.918 | train acc: 21.820% | lr: 0.100000
   == step: [200/391], train loss: 1.909 | train acc: 22.012% | lr: 0.100000
   == step: [300/391], train loss: 1.911 | train acc: 22.125% | lr: 0.100000
   == step: [391/391], train loss: 1.914 | train acc: 21.642% | lr: 0.100000
   == cost time: 41.2021s
 === Validate ===
   == test loss: 2.043 | test acc: 20.220%
 === Epoch: [5/250] === 
   == step: [100/391], train loss: 1.917 | train acc: 21.453% | lr: 0.100000
   == step: [200/391], train loss: 1.916 | train acc: 21.828% | lr: 0.100000
   == step: [300/391], train loss: 1.913 | train acc: 21.763% | lr: 0.100000
   == step: [391/391], train loss: 1.912 | train acc: 21.938% | lr: 0.100000
   == cost time: 41.9559s
 === Epoch: [6/250] === 
   == step: [100/391], train loss: 1.914 | train acc: 21.938% | lr: 0.100000
   == step: [200/391], train loss: 1.919 | train acc: 21.668% | lr: 0.100000
   == step: [300/391], train loss: 1.917 | train acc: 21.708% | lr: 0.100000
   == step: [391/391], train loss: 1.912 | train acc: 22.088% | lr: 0.100000
   == cost time: 42.1842s
 === Validate ===
   == test loss: 5.476 | test acc:  9.970%
 === Epoch: [7/250] === 
   == step: [100/391], train loss: 1.904 | train acc: 21.844% | lr: 0.100000
   == step: [200/391], train loss: 1.903 | train acc: 22.457% | lr: 0.100000
   == step: [300/391], train loss: 1.901 | train acc: 22.727% | lr: 0.100000
   == step: [391/391], train loss: 1.900 | train acc: 22.886% | lr: 0.100000
   == cost time: 42.9005s
 === Epoch: [8/250] === 
   == step: [100/391], train loss: 1.896 | train acc: 22.836% | lr: 0.100000
   == step: [200/391], train loss: 1.890 | train acc: 22.918% | lr: 0.100000
   == step: [300/391], train loss: 1.891 | train acc: 22.888% | lr: 0.100000
   == step: [391/391], train loss: 1.891 | train acc: 23.126% | lr: 0.100000
   == cost time: 48.6257s
 === Validate ===
   == test loss: 2.133 | test acc: 20.890%
 === Epoch: [9/250] === 
   == step: [100/391], train loss: 1.883 | train acc: 23.562% | lr: 0.100000
   == step: [200/391], train loss: 1.885 | train acc: 23.988% | lr: 0.100000
   == step: [300/391], train loss: 1.880 | train acc: 23.930% | lr: 0.100000
   == step: [391/391], train loss: 1.899 | train acc: 23.442% | lr: 0.100000
   == cost time: 41.3512s
 === Epoch: [10/250] === 
   == step: [100/391], train loss: 1.895 | train acc: 23.711% | lr: 0.100000
   == step: [200/391], train loss: 1.899 | train acc: 23.457% | lr: 0.100000
   == step: [300/391], train loss: 1.892 | train acc: 23.771% | lr: 0.100000
   == step: [391/391], train loss: 1.891 | train acc: 23.696% | lr: 0.100000
   == cost time: 43.1576s
 === Validate ===
   == test loss: 2.703 | test acc: 12.300%
 === Epoch: [11/250] === 
   == step: [100/391], train loss: 1.871 | train acc: 23.938% | lr: 0.100000
   == step: [200/391], train loss: 1.880 | train acc: 23.527% | lr: 0.100000
{'architecture': 'vgg16', 'data_path': './data', 'ckpt_path': './', 'ckpt_name': 'vgg16', 'num_classes': 10, 'dataset': 'cifar10', 'kernel_size': [5, 5, 3, 3, 3], 'use_gpu': True, 'input_size': 32, 'epochs': 250, 'batch_size': 128, 'test_batch': 200, 'eval_freq': 2, 'workers': 4, 'optimize': {'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': True}, 'mixup': False, 'mixup_alpha': 0.4, 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True, 'cutout': False, 'holes': 1, 'length': 8}, 'lr_scheduler': {'type': 'STEP', 'base_lr': 0.1, 'lr_epochs': [100, 150, 200], 'lr_mults': 0.1, 'min_lr': 0.0, 'lower_bound': -6.0, 'upper_bound': 3.0}}
{'architecture': 'vgg16', 'data_path': './data', 'ckpt_path': './', 'ckpt_name': 'vgg16', 'num_classes': 10, 'dataset': 'cifar10', 'kernel_size': [5, 5, 3, 3, 3], 'use_gpu': True, 'input_size': 32, 'epochs': 250, 'batch_size': 128, 'test_batch': 200, 'eval_freq': 2, 'workers': 4, 'optimize': {'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': True}, 'mixup': False, 'mixup_alpha': 0.4, 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True, 'cutout': False, 'holes': 1, 'length': 8}, 'lr_scheduler': {'type': 'STEP', 'base_lr': 0.1, 'lr_epochs': [100, 150, 200], 'lr_mults': 0.1, 'min_lr': 0.0, 'lower_bound': -6.0, 'upper_bound': 3.0}}
{'architecture': 'vgg16', 'data_path': './data', 'ckpt_path': './', 'ckpt_name': 'vgg16', 'num_classes': 10, 'dataset': 'cifar10', 'kernel_size': [5, 5, 3, 3, 3], 'use_gpu': True, 'input_size': 32, 'epochs': 250, 'batch_size': 128, 'test_batch': 200, 'eval_freq': 2, 'workers': 4, 'optimize': {'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': True}, 'mixup': False, 'mixup_alpha': 0.4, 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True, 'cutout': False, 'holes': 1, 'length': 8}, 'lr_scheduler': {'type': 'STEP', 'base_lr': 0.1, 'lr_epochs': [100, 150, 200], 'lr_mults': 0.1, 'min_lr': 0.0, 'lower_bound': -6.0, 'upper_bound': 3.0}}
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Linear(in_features=512, out_features=10, bias=True)
)
 == total parameters: 15190090
            =======  Training  =======

 === Epoch: [1/250] === 
{'architecture': 'vgg16', 'data_path': './data', 'ckpt_path': './', 'ckpt_name': 'vgg16', 'num_classes': 10, 'dataset': 'cifar10', 'kernel_size': [5, 5, 3, 3, 3], 'use_gpu': True, 'input_size': 32, 'epochs': 250, 'batch_size': 128, 'test_batch': 200, 'eval_freq': 2, 'workers': 4, 'optimize': {'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': True}, 'mixup': False, 'mixup_alpha': 0.4, 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True, 'cutout': False, 'holes': 1, 'length': 8}, 'lr_scheduler': {'type': 'STEP', 'base_lr': 0.001, 'lr_epochs': [100, 150, 200], 'lr_mults': 0.1, 'min_lr': 0.0, 'lower_bound': -6.0, 'upper_bound': 3.0}}
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
 == total parameters: 33646666
{'architecture': 'vgg16', 'data_path': './data', 'ckpt_path': './', 'ckpt_name': 'vgg16', 'num_classes': 10, 'dataset': 'cifar10', 'kernel_size': [5, 5, 3, 3, 3], 'use_gpu': True, 'input_size': 32, 'epochs': 250, 'batch_size': 128, 'test_batch': 200, 'eval_freq': 2, 'workers': 4, 'optimize': {'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': True}, 'mixup': False, 'mixup_alpha': 0.4, 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True, 'cutout': False, 'holes': 1, 'length': 8}, 'lr_scheduler': {'type': 'STEP', 'base_lr': 0.001, 'lr_epochs': [100, 150, 200], 'lr_mults': 0.1, 'min_lr': 0.0, 'lower_bound': -6.0, 'upper_bound': 3.0}}
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
 == total parameters: 33646666
            =======  Training  =======

 === Epoch: [1/250] === 
   == step: [100/391], train loss: 2.274 | train acc: 13.109% | lr: 0.001000
   == step: [200/391], train loss: 2.119 | train acc: 16.383% | lr: 0.001000
   == step: [300/391], train loss: 2.050 | train acc: 18.057% | lr: 0.001000
   == step: [391/391], train loss: 2.002 | train acc: 19.878% | lr: 0.001000
   == cost time: 50.5161s
 === Validate ===
   == test loss: 1.819 | test acc: 28.210%
 === Epoch: [2/250] === 
   == step: [100/391], train loss: 1.740 | train acc: 30.703% | lr: 0.001000
   == step: [200/391], train loss: 1.692 | train acc: 32.684% | lr: 0.001000
   == step: [300/391], train loss: 1.653 | train acc: 34.570% | lr: 0.001000
   == step: [391/391], train loss: 1.623 | train acc: 35.914% | lr: 0.001000
   == cost time: 41.1620s
 === Validate ===
   == test loss: 1.657 | test acc: 37.910%
 === Epoch: [3/250] === 
   == step: [100/391], train loss: 1.476 | train acc: 42.859% | lr: 0.001000
   == step: [200/391], train loss: 1.449 | train acc: 45.012% | lr: 0.001000
   == step: [300/391], train loss: 1.419 | train acc: 46.750% | lr: 0.001000
   == step: [391/391], train loss: 1.393 | train acc: 48.074% | lr: 0.001000
   == cost time: 41.1705s
 === Epoch: [4/250] === 
   == step: [100/391], train loss: 1.251 | train acc: 54.914% | lr: 0.001000
   == step: [200/391], train loss: 1.239 | train acc: 55.410% | lr: 0.001000
   == step: [300/391], train loss: 1.218 | train acc: 56.289% | lr: 0.001000
   == step: [391/391], train loss: 1.193 | train acc: 57.218% | lr: 0.001000
   == cost time: 42.2667s
 === Validate ===
   == test loss: 1.042 | test acc: 62.730%
 === Epoch: [5/250] === 
   == step: [100/391], train loss: 1.093 | train acc: 61.539% | lr: 0.001000
   == step: [200/391], train loss: 1.068 | train acc: 62.492% | lr: 0.001000
   == step: [300/391], train loss: 1.047 | train acc: 63.375% | lr: 0.001000
   == step: [391/391], train loss: 1.033 | train acc: 63.952% | lr: 0.001000
   == cost time: 43.2238s
 === Epoch: [6/250] === 
   == step: [100/391], train loss: 0.938 | train acc: 68.055% | lr: 0.001000
   == step: [200/391], train loss: 0.944 | train acc: 67.824% | lr: 0.001000
   == step: [300/391], train loss: 0.925 | train acc: 68.570% | lr: 0.001000
   == step: [391/391], train loss: 0.918 | train acc: 68.864% | lr: 0.001000
   == cost time: 42.0034s
 === Validate ===
   == test loss: 0.953 | test acc: 67.620%
 === Epoch: [7/250] === 
   == step: [100/391], train loss: 0.854 | train acc: 71.461% | lr: 0.001000
   == step: [200/391], train loss: 0.844 | train acc: 71.871% | lr: 0.001000
   == step: [300/391], train loss: 0.840 | train acc: 72.000% | lr: 0.001000
   == step: [391/391], train loss: 0.832 | train acc: 72.306% | lr: 0.001000
   == cost time: 47.2321s
 === Epoch: [8/250] === 
   == step: [100/391], train loss: 0.767 | train acc: 74.750% | lr: 0.001000
   == step: [200/391], train loss: 0.775 | train acc: 74.754% | lr: 0.001000
   == step: [300/391], train loss: 0.764 | train acc: 75.094% | lr: 0.001000
   == step: [391/391], train loss: 0.761 | train acc: 75.234% | lr: 0.001000
   == cost time: 47.5255s
 === Validate ===
   == test loss: 0.733 | test acc: 76.290%
 === Epoch: [9/250] === 
   == step: [100/391], train loss: 0.722 | train acc: 76.969% | lr: 0.001000
   == step: [200/391], train loss: 0.715 | train acc: 77.254% | lr: 0.001000
   == step: [300/391], train loss: 0.711 | train acc: 77.188% | lr: 0.001000
   == step: [391/391], train loss: 0.701 | train acc: 77.582% | lr: 0.001000
   == cost time: 44.9249s
 === Epoch: [10/250] === 
   == step: [100/391], train loss: 0.671 | train acc: 78.586% | lr: 0.001000
   == step: [200/391], train loss: 0.660 | train acc: 78.887% | lr: 0.001000
   == step: [300/391], train loss: 0.654 | train acc: 79.174% | lr: 0.001000
   == step: [391/391], train loss: 0.653 | train acc: 79.374% | lr: 0.001000
   == cost time: 44.8067s
 === Validate ===
   == test loss: 0.689 | test acc: 78.120%
 === Epoch: [11/250] === 
   == step: [100/391], train loss: 0.619 | train acc: 80.672% | lr: 0.001000
   == step: [200/391], train loss: 0.610 | train acc: 81.078% | lr: 0.001000
   == step: [300/391], train loss: 0.608 | train acc: 81.089% | lr: 0.001000
   == step: [391/391], train loss: 0.612 | train acc: 81.082% | lr: 0.001000
   == cost time: 44.8162s
 === Epoch: [12/250] === 
   == step: [100/391], train loss: 0.563 | train acc: 82.617% | lr: 0.001000
   == step: [200/391], train loss: 0.570 | train acc: 82.484% | lr: 0.001000
   == step: [300/391], train loss: 0.567 | train acc: 82.521% | lr: 0.001000
   == step: [391/391], train loss: 0.563 | train acc: 82.618% | lr: 0.001000
   == cost time: 45.2988s
 === Validate ===
   == test loss: 0.670 | test acc: 78.420%
 === Epoch: [13/250] === 
   == step: [100/391], train loss: 0.515 | train acc: 83.828% | lr: 0.001000
   == step: [200/391], train loss: 0.531 | train acc: 83.488% | lr: 0.001000
   == step: [300/391], train loss: 0.530 | train acc: 83.609% | lr: 0.001000
   == step: [391/391], train loss: 0.529 | train acc: 83.642% | lr: 0.001000
   == cost time: 44.7188s
 === Epoch: [14/250] === 
   == step: [100/391], train loss: 0.491 | train acc: 84.773% | lr: 0.001000
   == step: [200/391], train loss: 0.490 | train acc: 84.582% | lr: 0.001000
   == step: [300/391], train loss: 0.495 | train acc: 84.570% | lr: 0.001000
   == step: [391/391], train loss: 0.497 | train acc: 84.630% | lr: 0.001000
   == cost time: 44.9045s
 === Validate ===
   == test loss: 0.678 | test acc: 79.130%
 === Epoch: [15/250] === 
   == step: [100/391], train loss: 0.502 | train acc: 84.305% | lr: 0.001000
   == step: [200/391], train loss: 0.492 | train acc: 84.781% | lr: 0.001000
   == step: [300/391], train loss: 0.486 | train acc: 85.036% | lr: 0.001000
   == step: [391/391], train loss: 0.482 | train acc: 85.060% | lr: 0.001000
   == cost time: 44.7451s
 === Epoch: [16/250] === 
   == step: [100/391], train loss: 0.435 | train acc: 86.391% | lr: 0.001000
   == step: [200/391], train loss: 0.437 | train acc: 86.324% | lr: 0.001000
   == step: [300/391], train loss: 0.443 | train acc: 86.104% | lr: 0.001000
   == step: [391/391], train loss: 0.443 | train acc: 86.188% | lr: 0.001000
   == cost time: 44.6474s
 === Validate ===
   == test loss: 0.484 | test acc: 84.960%
 === Epoch: [17/250] === 
   == step: [100/391], train loss: 0.431 | train acc: 86.539% | lr: 0.001000
   == step: [200/391], train loss: 0.431 | train acc: 86.484% | lr: 0.001000
   == step: [300/391], train loss: 0.439 | train acc: 86.258% | lr: 0.001000
   == step: [391/391], train loss: 0.439 | train acc: 86.306% | lr: 0.001000
   == cost time: 44.5498s
 === Epoch: [18/250] === 
   == step: [100/391], train loss: 0.406 | train acc: 87.586% | lr: 0.001000
   == step: [200/391], train loss: 0.407 | train acc: 87.277% | lr: 0.001000
   == step: [300/391], train loss: 0.404 | train acc: 87.396% | lr: 0.001000
   == step: [391/391], train loss: 0.404 | train acc: 87.358% | lr: 0.001000
   == cost time: 44.5621s
 === Validate ===
   == test loss: 0.502 | test acc: 84.440%
 === Epoch: [19/250] === 
   == step: [100/391], train loss: 0.382 | train acc: 88.148% | lr: 0.001000
   == step: [200/391], train loss: 0.385 | train acc: 88.047% | lr: 0.001000
   == step: [300/391], train loss: 0.387 | train acc: 88.055% | lr: 0.001000
   == step: [391/391], train loss: 0.392 | train acc: 87.928% | lr: 0.001000
   == cost time: 44.5300s
 === Epoch: [20/250] === 
   == step: [100/391], train loss: 0.372 | train acc: 88.117% | lr: 0.001000
   == step: [200/391], train loss: 0.371 | train acc: 88.273% | lr: 0.001000
   == step: [300/391], train loss: 0.370 | train acc: 88.333% | lr: 0.001000
   == step: [391/391], train loss: 0.371 | train acc: 88.372% | lr: 0.001000
   == cost time: 44.6451s
 === Validate ===
   == test loss: 0.476 | test acc: 85.350%
 === Epoch: [21/250] === 
   == step: [100/391], train loss: 0.345 | train acc: 89.445% | lr: 0.001000
   == step: [200/391], train loss: 0.353 | train acc: 89.094% | lr: 0.001000
   == step: [300/391], train loss: 0.356 | train acc: 88.964% | lr: 0.001000
   == step: [391/391], train loss: 0.365 | train acc: 88.658% | lr: 0.001000
   == cost time: 44.5536s
 === Epoch: [22/250] === 
   == step: [100/391], train loss: 0.342 | train acc: 89.367% | lr: 0.001000
   == step: [200/391], train loss: 0.338 | train acc: 89.488% | lr: 0.001000
   == step: [300/391], train loss: 0.339 | train acc: 89.539% | lr: 0.001000
   == step: [391/391], train loss: 0.341 | train acc: 89.376% | lr: 0.001000
   == cost time: 44.6785s
 === Validate ===
   == test loss: 0.437 | test acc: 86.350%
 === Epoch: [23/250] === 
   == step: [100/391], train loss: 0.324 | train acc: 89.914% | lr: 0.001000
   == step: [200/391], train loss: 0.326 | train acc: 89.766% | lr: 0.001000
   == step: [300/391], train loss: 0.329 | train acc: 89.685% | lr: 0.001000
   == step: [391/391], train loss: 0.329 | train acc: 89.680% | lr: 0.001000
   == cost time: 44.4907s
 === Epoch: [24/250] === 
   == step: [100/391], train loss: 0.323 | train acc: 89.906% | lr: 0.001000
   == step: [200/391], train loss: 0.316 | train acc: 90.254% | lr: 0.001000
   == step: [300/391], train loss: 0.321 | train acc: 90.104% | lr: 0.001000
   == step: [391/391], train loss: 0.322 | train acc: 90.030% | lr: 0.001000
   == cost time: 44.4355s
 === Validate ===
   == test loss: 0.408 | test acc: 87.220%
 === Epoch: [25/250] === 
   == step: [100/391], train loss: 0.293 | train acc: 90.750% | lr: 0.001000
   == step: [200/391], train loss: 0.302 | train acc: 90.398% | lr: 0.001000
   == step: [300/391], train loss: 0.310 | train acc: 90.182% | lr: 0.001000
   == step: [391/391], train loss: 0.311 | train acc: 90.192% | lr: 0.001000
   == cost time: 44.3166s
 === Epoch: [26/250] === 
   == step: [100/391], train loss: 0.282 | train acc: 91.336% | lr: 0.001000
   == step: [200/391], train loss: 0.294 | train acc: 90.848% | lr: 0.001000
   == step: [300/391], train loss: 0.298 | train acc: 90.792% | lr: 0.001000
   == step: [391/391], train loss: 0.301 | train acc: 90.702% | lr: 0.001000
   == cost time: 44.8100s
 === Validate ===
   == test loss: 0.447 | test acc: 86.450%
 === Epoch: [27/250] === 
   == step: [100/391], train loss: 0.277 | train acc: 91.539% | lr: 0.001000
   == step: [200/391], train loss: 0.281 | train acc: 91.418% | lr: 0.001000
   == step: [300/391], train loss: 0.288 | train acc: 91.195% | lr: 0.001000
   == step: [391/391], train loss: 0.293 | train acc: 91.054% | lr: 0.001000
   == cost time: 44.1435s
 === Epoch: [28/250] === 
   == step: [100/391], train loss: 0.266 | train acc: 91.664% | lr: 0.001000
   == step: [200/391], train loss: 0.277 | train acc: 91.262% | lr: 0.001000
   == step: [300/391], train loss: 0.277 | train acc: 91.266% | lr: 0.001000
   == step: [391/391], train loss: 0.280 | train acc: 91.176% | lr: 0.001000
   == cost time: 44.5487s
 === Validate ===
   == test loss: 0.465 | test acc: 86.270%
 === Epoch: [29/250] === 
   == step: [100/391], train loss: 0.251 | train acc: 92.297% | lr: 0.001000
   == step: [200/391], train loss: 0.260 | train acc: 92.031% | lr: 0.001000
   == step: [300/391], train loss: 0.269 | train acc: 91.688% | lr: 0.001000
   == step: [391/391], train loss: 0.271 | train acc: 91.600% | lr: 0.001000
   == cost time: 44.2606s
 === Epoch: [30/250] === 
   == step: [100/391], train loss: 0.259 | train acc: 91.898% | lr: 0.001000
   == step: [200/391], train loss: 0.260 | train acc: 91.945% | lr: 0.001000
   == step: [300/391], train loss: 0.261 | train acc: 91.818% | lr: 0.001000
   == step: [391/391], train loss: 0.263 | train acc: 91.720% | lr: 0.001000
   == cost time: 44.3770s
 === Validate ===
   == test loss: 0.421 | test acc: 87.430%
 === Epoch: [31/250] === 
   == step: [100/391], train loss: 0.250 | train acc: 92.125% | lr: 0.001000
   == step: [200/391], train loss: 0.250 | train acc: 92.270% | lr: 0.001000
   == step: [300/391], train loss: 0.254 | train acc: 92.109% | lr: 0.001000
   == step: [391/391], train loss: 0.254 | train acc: 92.060% | lr: 0.001000
   == cost time: 44.3485s
 === Epoch: [32/250] === 
   == step: [100/391], train loss: 0.234 | train acc: 92.617% | lr: 0.001000
   == step: [200/391], train loss: 0.242 | train acc: 92.418% | lr: 0.001000
   == step: [300/391], train loss: 0.245 | train acc: 92.268% | lr: 0.001000
   == step: [391/391], train loss: 0.250 | train acc: 92.112% | lr: 0.001000
   == cost time: 44.4783s
 === Validate ===
   == test loss: 0.410 | test acc: 87.790%
 === Epoch: [33/250] === 
   == step: [100/391], train loss: 0.233 | train acc: 92.828% | lr: 0.001000
   == step: [200/391], train loss: 0.230 | train acc: 92.852% | lr: 0.001000
   == step: [300/391], train loss: 0.239 | train acc: 92.570% | lr: 0.001000
   == step: [391/391], train loss: 0.241 | train acc: 92.546% | lr: 0.001000
   == cost time: 44.2594s
 === Epoch: [34/250] === 
   == step: [100/391], train loss: 0.224 | train acc: 93.273% | lr: 0.001000
   == step: [200/391], train loss: 0.228 | train acc: 93.051% | lr: 0.001000
   == step: [300/391], train loss: 0.230 | train acc: 92.945% | lr: 0.001000
   == step: [391/391], train loss: 0.234 | train acc: 92.810% | lr: 0.001000
   == cost time: 44.3785s
 === Validate ===
   == test loss: 0.458 | test acc: 87.260%
 === Epoch: [35/250] === 
   == step: [100/391], train loss: 0.235 | train acc: 92.688% | lr: 0.001000
   == step: [200/391], train loss: 0.226 | train acc: 93.012% | lr: 0.001000
   == step: [300/391], train loss: 0.228 | train acc: 92.909% | lr: 0.001000
   == step: [391/391], train loss: 0.230 | train acc: 92.788% | lr: 0.001000
   == cost time: 44.4488s
 === Epoch: [36/250] === 
   == step: [100/391], train loss: 0.207 | train acc: 93.555% | lr: 0.001000
   == step: [200/391], train loss: 0.212 | train acc: 93.340% | lr: 0.001000
   == step: [300/391], train loss: 0.217 | train acc: 93.188% | lr: 0.001000
   == step: [391/391], train loss: 0.223 | train acc: 93.030% | lr: 0.001000
   == cost time: 44.3104s
 === Validate ===
   == test loss: 0.367 | test acc: 89.340%
 === Epoch: [37/250] === 
   == step: [100/391], train loss: 0.226 | train acc: 93.125% | lr: 0.001000
   == step: [200/391], train loss: 0.216 | train acc: 93.496% | lr: 0.001000
   == step: [300/391], train loss: 0.218 | train acc: 93.320% | lr: 0.001000
   == step: [391/391], train loss: 0.224 | train acc: 93.156% | lr: 0.001000
   == cost time: 44.4342s
 === Epoch: [38/250] === 
   == step: [100/391], train loss: 0.221 | train acc: 93.289% | lr: 0.001000
   == step: [200/391], train loss: 0.217 | train acc: 93.344% | lr: 0.001000
   == step: [300/391], train loss: 0.220 | train acc: 93.159% | lr: 0.001000
   == step: [391/391], train loss: 0.224 | train acc: 93.042% | lr: 0.001000
   == cost time: 47.1022s
 === Validate ===
   == test loss: 0.375 | test acc: 88.770%
 === Epoch: [39/250] === 
   == step: [100/391], train loss: 0.204 | train acc: 93.805% | lr: 0.001000
   == step: [200/391], train loss: 0.209 | train acc: 93.547% | lr: 0.001000
   == step: [300/391], train loss: 0.213 | train acc: 93.375% | lr: 0.001000
   == step: [391/391], train loss: 0.217 | train acc: 93.244% | lr: 0.001000
   == cost time: 44.0372s
 === Epoch: [40/250] === 
   == step: [100/391], train loss: 0.196 | train acc: 94.047% | lr: 0.001000
   == step: [200/391], train loss: 0.198 | train acc: 93.891% | lr: 0.001000
   == step: [300/391], train loss: 0.203 | train acc: 93.734% | lr: 0.001000
   == step: [391/391], train loss: 0.206 | train acc: 93.600% | lr: 0.001000
   == cost time: 44.4687s
 === Validate ===
   == test loss: 0.387 | test acc: 88.820%
 === Epoch: [41/250] === 
   == step: [100/391], train loss: 0.200 | train acc: 93.969% | lr: 0.001000
   == step: [200/391], train loss: 0.200 | train acc: 93.824% | lr: 0.001000
   == step: [300/391], train loss: 0.201 | train acc: 93.763% | lr: 0.001000
   == step: [391/391], train loss: 0.203 | train acc: 93.716% | lr: 0.001000
   == cost time: 44.1677s
 === Epoch: [42/250] === 
   == step: [100/391], train loss: 0.203 | train acc: 93.734% | lr: 0.001000
   == step: [200/391], train loss: 0.204 | train acc: 93.730% | lr: 0.001000
   == step: [300/391], train loss: 0.204 | train acc: 93.708% | lr: 0.001000
   == step: [391/391], train loss: 0.204 | train acc: 93.710% | lr: 0.001000
   == cost time: 44.4900s
 === Validate ===
   == test loss: 0.382 | test acc: 88.820%
 === Epoch: [43/250] === 
   == step: [100/391], train loss: 0.187 | train acc: 94.203% | lr: 0.001000
   == step: [200/391], train loss: 0.193 | train acc: 94.012% | lr: 0.001000
   == step: [300/391], train loss: 0.200 | train acc: 93.901% | lr: 0.001000
   == step: [391/391], train loss: 0.201 | train acc: 93.792% | lr: 0.001000
   == cost time: 44.2337s
 === Epoch: [44/250] === 
   == step: [100/391], train loss: 0.179 | train acc: 94.461% | lr: 0.001000
   == step: [200/391], train loss: 0.188 | train acc: 94.160% | lr: 0.001000
   == step: [300/391], train loss: 0.192 | train acc: 94.107% | lr: 0.001000
   == step: [391/391], train loss: 0.195 | train acc: 94.042% | lr: 0.001000
   == cost time: 44.5450s
 === Validate ===
   == test loss: 0.402 | test acc: 89.090%
 === Epoch: [45/250] === 
   == step: [100/391], train loss: 0.182 | train acc: 94.344% | lr: 0.001000
   == step: [200/391], train loss: 0.194 | train acc: 93.992% | lr: 0.001000
   == step: [300/391], train loss: 0.191 | train acc: 94.047% | lr: 0.001000
   == step: [391/391], train loss: 0.193 | train acc: 93.984% | lr: 0.001000
   == cost time: 44.5281s
 === Epoch: [46/250] === 
   == step: [100/391], train loss: 0.169 | train acc: 94.625% | lr: 0.001000
   == step: [200/391], train loss: 0.180 | train acc: 94.453% | lr: 0.001000
   == step: [300/391], train loss: 0.185 | train acc: 94.336% | lr: 0.001000
   == step: [391/391], train loss: 0.186 | train acc: 94.254% | lr: 0.001000
   == cost time: 44.4995s
 === Validate ===
   == test loss: 0.478 | test acc: 86.920%
 === Epoch: [47/250] === 
   == step: [100/391], train loss: 0.175 | train acc: 94.547% | lr: 0.001000
   == step: [200/391], train loss: 0.183 | train acc: 94.383% | lr: 0.001000
   == step: [300/391], train loss: 0.186 | train acc: 94.247% | lr: 0.001000
   == step: [391/391], train loss: 0.190 | train acc: 94.096% | lr: 0.001000
   == cost time: 44.8866s
 === Epoch: [48/250] === 
   == step: [100/391], train loss: 0.175 | train acc: 94.500% | lr: 0.001000
   == step: [200/391], train loss: 0.184 | train acc: 94.344% | lr: 0.001000
   == step: [300/391], train loss: 0.185 | train acc: 94.341% | lr: 0.001000
   == step: [391/391], train loss: 0.188 | train acc: 94.218% | lr: 0.001000
   == cost time: 44.3352s
 === Validate ===
   == test loss: 0.385 | test acc: 88.720%
 === Epoch: [49/250] === 
   == step: [100/391], train loss: 0.168 | train acc: 94.906% | lr: 0.001000
   == step: [200/391], train loss: 0.173 | train acc: 94.746% | lr: 0.001000
   == step: [300/391], train loss: 0.176 | train acc: 94.659% | lr: 0.001000
   == step: [391/391], train loss: 0.179 | train acc: 94.484% | lr: 0.001000
   == cost time: 44.3219s
 === Epoch: [50/250] === 
   == step: [100/391], train loss: 0.167 | train acc: 94.812% | lr: 0.001000
   == step: [200/391], train loss: 0.171 | train acc: 94.703% | lr: 0.001000
   == step: [300/391], train loss: 0.174 | train acc: 94.615% | lr: 0.001000
   == step: [391/391], train loss: 0.181 | train acc: 94.360% | lr: 0.001000
   == cost time: 44.3598s
 === Validate ===
   == test loss: 0.388 | test acc: 88.900%
 === Epoch: [51/250] === 
   == step: [100/391], train loss: 0.159 | train acc: 95.078% | lr: 0.001000
   == step: [200/391], train loss: 0.166 | train acc: 94.664% | lr: 0.001000
   == step: [300/391], train loss: 0.170 | train acc: 94.607% | lr: 0.001000
   == step: [391/391], train loss: 0.176 | train acc: 94.496% | lr: 0.001000
   == cost time: 44.3050s
 === Epoch: [52/250] === 
   == step: [100/391], train loss: 0.173 | train acc: 94.562% | lr: 0.001000
   == step: [200/391], train loss: 0.178 | train acc: 94.379% | lr: 0.001000
   == step: [300/391], train loss: 0.175 | train acc: 94.432% | lr: 0.001000
   == step: [391/391], train loss: 0.176 | train acc: 94.410% | lr: 0.001000
   == cost time: 44.4518s
 === Validate ===
   == test loss: 0.379 | test acc: 89.530%
 === Epoch: [53/250] === 
   == step: [100/391], train loss: 0.165 | train acc: 94.922% | lr: 0.001000
   == step: [200/391], train loss: 0.164 | train acc: 94.855% | lr: 0.001000
   == step: [300/391], train loss: 0.165 | train acc: 94.818% | lr: 0.001000
   == step: [391/391], train loss: 0.171 | train acc: 94.640% | lr: 0.001000
   == cost time: 43.9979s
 === Epoch: [54/250] === 
   == step: [100/391], train loss: 0.164 | train acc: 95.172% | lr: 0.001000
   == step: [200/391], train loss: 0.165 | train acc: 95.043% | lr: 0.001000
   == step: [300/391], train loss: 0.166 | train acc: 94.974% | lr: 0.001000
   == step: [391/391], train loss: 0.169 | train acc: 94.858% | lr: 0.001000
   == cost time: 44.1861s
 === Validate ===
   == test loss: 0.380 | test acc: 89.440%
 === Epoch: [55/250] === 
   == step: [100/391], train loss: 0.153 | train acc: 95.320% | lr: 0.001000
   == step: [200/391], train loss: 0.158 | train acc: 95.012% | lr: 0.001000
   == step: [300/391], train loss: 0.163 | train acc: 94.940% | lr: 0.001000
   == step: [391/391], train loss: 0.164 | train acc: 94.900% | lr: 0.001000
   == cost time: 48.3961s
 === Epoch: [56/250] === 
   == step: [100/391], train loss: 0.154 | train acc: 95.180% | lr: 0.001000
   == step: [200/391], train loss: 0.164 | train acc: 95.016% | lr: 0.001000
   == step: [300/391], train loss: 0.165 | train acc: 94.964% | lr: 0.001000
   == step: [391/391], train loss: 0.167 | train acc: 94.856% | lr: 0.001000
   == cost time: 46.5439s
 === Validate ===
   == test loss: 0.444 | test acc: 88.280%
 === Epoch: [57/250] === 
   == step: [100/391], train loss: 0.151 | train acc: 95.320% | lr: 0.001000
   == step: [200/391], train loss: 0.153 | train acc: 95.297% | lr: 0.001000
   == step: [300/391], train loss: 0.157 | train acc: 95.154% | lr: 0.001000
   == step: [391/391], train loss: 0.159 | train acc: 95.042% | lr: 0.001000
   == cost time: 45.8911s
 === Epoch: [58/250] === 
   == step: [100/391], train loss: 0.153 | train acc: 95.391% | lr: 0.001000
   == step: [200/391], train loss: 0.159 | train acc: 95.141% | lr: 0.001000
   == step: [300/391], train loss: 0.163 | train acc: 94.956% | lr: 0.001000
   == step: [391/391], train loss: 0.166 | train acc: 94.874% | lr: 0.001000
   == cost time: 46.1950s
 === Validate ===
   == test loss: 0.378 | test acc: 89.370%
 === Epoch: [59/250] === 
   == step: [100/391], train loss: 0.143 | train acc: 95.484% | lr: 0.001000
   == step: [200/391], train loss: 0.152 | train acc: 95.297% | lr: 0.001000
   == step: [300/391], train loss: 0.153 | train acc: 95.234% | lr: 0.001000
   == step: [391/391], train loss: 0.158 | train acc: 95.102% | lr: 0.001000
   == cost time: 46.6802s
 === Epoch: [60/250] === 
   == step: [100/391], train loss: 0.144 | train acc: 95.680% | lr: 0.001000
   == step: [200/391], train loss: 0.150 | train acc: 95.473% | lr: 0.001000
   == step: [300/391], train loss: 0.155 | train acc: 95.357% | lr: 0.001000
   == step: [391/391], train loss: 0.157 | train acc: 95.260% | lr: 0.001000
   == cost time: 45.7199s
 === Validate ===
   == test loss: 0.379 | test acc: 89.400%
 === Epoch: [61/250] === 
   == step: [100/391], train loss: 0.143 | train acc: 95.594% | lr: 0.001000
   == step: [200/391], train loss: 0.150 | train acc: 95.379% | lr: 0.001000
   == step: [300/391], train loss: 0.155 | train acc: 95.216% | lr: 0.001000
   == step: [391/391], train loss: 0.156 | train acc: 95.164% | lr: 0.001000
   == cost time: 43.4786s
 === Epoch: [62/250] === 
   == step: [100/391], train loss: 0.152 | train acc: 95.391% | lr: 0.001000
   == step: [200/391], train loss: 0.152 | train acc: 95.328% | lr: 0.001000
   == step: [300/391], train loss: 0.157 | train acc: 95.195% | lr: 0.001000
   == step: [391/391], train loss: 0.158 | train acc: 95.162% | lr: 0.001000
   == cost time: 44.3936s
 === Validate ===
   == test loss: 0.431 | test acc: 88.600%
 === Epoch: [63/250] === 
   == step: [100/391], train loss: 0.155 | train acc: 95.328% | lr: 0.001000
   == step: [200/391], train loss: 0.153 | train acc: 95.340% | lr: 0.001000
   == step: [300/391], train loss: 0.158 | train acc: 95.154% | lr: 0.001000
   == step: [391/391], train loss: 0.159 | train acc: 95.128% | lr: 0.001000
   == cost time: 44.0760s
 === Epoch: [64/250] === 
   == step: [100/391], train loss: 0.144 | train acc: 95.531% | lr: 0.001000
   == step: [200/391], train loss: 0.146 | train acc: 95.574% | lr: 0.001000
   == step: [300/391], train loss: 0.146 | train acc: 95.531% | lr: 0.001000
   == step: [391/391], train loss: 0.149 | train acc: 95.454% | lr: 0.001000
   == cost time: 44.1866s
 === Validate ===
   == test loss: 0.419 | test acc: 88.640%
 === Epoch: [65/250] === 
   == step: [100/391], train loss: 0.141 | train acc: 95.797% | lr: 0.001000
   == step: [200/391], train loss: 0.150 | train acc: 95.562% | lr: 0.001000
   == step: [300/391], train loss: 0.152 | train acc: 95.396% | lr: 0.001000
   == step: [391/391], train loss: 0.154 | train acc: 95.310% | lr: 0.001000
   == cost time: 44.4262s
 === Epoch: [66/250] === 
   == step: [100/391], train loss: 0.138 | train acc: 95.828% | lr: 0.001000
   == step: [200/391], train loss: 0.147 | train acc: 95.457% | lr: 0.001000
   == step: [300/391], train loss: 0.147 | train acc: 95.432% | lr: 0.001000
   == step: [391/391], train loss: 0.150 | train acc: 95.342% | lr: 0.001000
   == cost time: 44.3667s
 === Validate ===
   == test loss: 0.388 | test acc: 89.610%
 === Epoch: [67/250] === 
   == step: [100/391], train loss: 0.146 | train acc: 95.492% | lr: 0.001000
   == step: [200/391], train loss: 0.144 | train acc: 95.555% | lr: 0.001000
   == step: [300/391], train loss: 0.148 | train acc: 95.469% | lr: 0.001000
   == step: [391/391], train loss: 0.151 | train acc: 95.388% | lr: 0.001000
   == cost time: 44.2078s
 === Epoch: [68/250] === 
   == step: [100/391], train loss: 0.145 | train acc: 95.492% | lr: 0.001000
   == step: [200/391], train loss: 0.145 | train acc: 95.449% | lr: 0.001000
   == step: [300/391], train loss: 0.147 | train acc: 95.456% | lr: 0.001000
   == step: [391/391], train loss: 0.148 | train acc: 95.348% | lr: 0.001000
   == cost time: 44.3220s
 === Validate ===
   == test loss: 0.442 | test acc: 88.670%
 === Epoch: [69/250] === 
   == step: [100/391], train loss: 0.140 | train acc: 95.562% | lr: 0.001000
   == step: [200/391], train loss: 0.142 | train acc: 95.469% | lr: 0.001000
   == step: [300/391], train loss: 0.145 | train acc: 95.424% | lr: 0.001000
   == step: [391/391], train loss: 0.144 | train acc: 95.522% | lr: 0.001000
   == cost time: 43.9591s
 === Epoch: [70/250] === 
   == step: [100/391], train loss: 0.133 | train acc: 95.969% | lr: 0.001000
   == step: [200/391], train loss: 0.147 | train acc: 95.484% | lr: 0.001000
   == step: [300/391], train loss: 0.147 | train acc: 95.445% | lr: 0.001000
   == step: [391/391], train loss: 0.148 | train acc: 95.400% | lr: 0.001000
   == cost time: 44.2065s
 === Validate ===
   == test loss: 0.388 | test acc: 89.620%
 === Epoch: [71/250] === 
   == step: [100/391], train loss: 0.133 | train acc: 95.906% | lr: 0.001000
   == step: [200/391], train loss: 0.142 | train acc: 95.676% | lr: 0.001000
   == step: [300/391], train loss: 0.145 | train acc: 95.607% | lr: 0.001000
   == step: [391/391], train loss: 0.148 | train acc: 95.498% | lr: 0.001000
   == cost time: 44.1150s
 === Epoch: [72/250] === 
   == step: [100/391], train loss: 0.140 | train acc: 95.656% | lr: 0.001000
   == step: [200/391], train loss: 0.142 | train acc: 95.535% | lr: 0.001000
   == step: [300/391], train loss: 0.144 | train acc: 95.445% | lr: 0.001000
   == step: [391/391], train loss: 0.147 | train acc: 95.386% | lr: 0.001000
   == cost time: 44.5536s
 === Validate ===
   == test loss: 0.360 | test acc: 89.720%
 === Epoch: [73/250] === 
   == step: [100/391], train loss: 0.132 | train acc: 95.820% | lr: 0.001000
   == step: [200/391], train loss: 0.135 | train acc: 95.828% | lr: 0.001000
   == step: [300/391], train loss: 0.143 | train acc: 95.516% | lr: 0.001000
   == step: [391/391], train loss: 0.146 | train acc: 95.440% | lr: 0.001000
   == cost time: 44.1006s
 === Epoch: [74/250] === 
   == step: [100/391], train loss: 0.122 | train acc: 96.180% | lr: 0.001000
   == step: [200/391], train loss: 0.130 | train acc: 95.941% | lr: 0.001000
   == step: [300/391], train loss: 0.138 | train acc: 95.646% | lr: 0.001000
   == step: [391/391], train loss: 0.141 | train acc: 95.542% | lr: 0.001000
   == cost time: 44.3735s
 === Validate ===
   == test loss: 0.386 | test acc: 89.170%
 === Epoch: [75/250] === 
   == step: [100/391], train loss: 0.128 | train acc: 96.133% | lr: 0.001000
   == step: [200/391], train loss: 0.126 | train acc: 96.168% | lr: 0.001000
   == step: [300/391], train loss: 0.131 | train acc: 96.010% | lr: 0.001000
   == step: [391/391], train loss: 0.135 | train acc: 95.870% | lr: 0.001000
   == cost time: 44.1406s
 === Epoch: [76/250] === 
   == step: [100/391], train loss: 0.124 | train acc: 96.031% | lr: 0.001000
   == step: [200/391], train loss: 0.136 | train acc: 95.773% | lr: 0.001000
   == step: [300/391], train loss: 0.139 | train acc: 95.690% | lr: 0.001000
   == step: [391/391], train loss: 0.140 | train acc: 95.624% | lr: 0.001000
   == cost time: 44.2241s
 === Validate ===
   == test loss: 0.384 | test acc: 90.040%
 === Epoch: [77/250] === 
   == step: [100/391], train loss: 0.131 | train acc: 96.000% | lr: 0.001000
   == step: [200/391], train loss: 0.129 | train acc: 96.004% | lr: 0.001000
   == step: [300/391], train loss: 0.136 | train acc: 95.797% | lr: 0.001000
   == step: [391/391], train loss: 0.140 | train acc: 95.692% | lr: 0.001000
   == cost time: 44.1457s
 === Epoch: [78/250] === 
   == step: [100/391], train loss: 0.124 | train acc: 96.258% | lr: 0.001000
   == step: [200/391], train loss: 0.126 | train acc: 96.105% | lr: 0.001000
   == step: [300/391], train loss: 0.134 | train acc: 95.911% | lr: 0.001000
   == step: [391/391], train loss: 0.137 | train acc: 95.792% | lr: 0.001000
   == cost time: 44.3832s
 === Validate ===
   == test loss: 0.424 | test acc: 88.900%
 === Epoch: [79/250] === 
   == step: [100/391], train loss: 0.125 | train acc: 96.078% | lr: 0.001000
   == step: [200/391], train loss: 0.125 | train acc: 96.070% | lr: 0.001000
   == step: [300/391], train loss: 0.127 | train acc: 96.049% | lr: 0.001000
   == step: [391/391], train loss: 0.132 | train acc: 95.878% | lr: 0.001000
   == cost time: 44.1409s
 === Epoch: [80/250] === 
   == step: [100/391], train loss: 0.115 | train acc: 96.547% | lr: 0.001000
   == step: [200/391], train loss: 0.134 | train acc: 95.941% | lr: 0.001000
   == step: [300/391], train loss: 0.135 | train acc: 95.841% | lr: 0.001000
   == step: [391/391], train loss: 0.135 | train acc: 95.862% | lr: 0.001000
   == cost time: 44.4793s
 === Validate ===
   == test loss: 0.399 | test acc: 89.770%
 === Epoch: [81/250] === 
   == step: [100/391], train loss: 0.127 | train acc: 96.148% | lr: 0.001000
   == step: [200/391], train loss: 0.132 | train acc: 95.883% | lr: 0.001000
   == step: [300/391], train loss: 0.136 | train acc: 95.786% | lr: 0.001000
   == step: [391/391], train loss: 0.139 | train acc: 95.654% | lr: 0.001000
   == cost time: 44.0349s
 === Epoch: [82/250] === 
   == step: [100/391], train loss: 0.112 | train acc: 96.539% | lr: 0.001000
   == step: [200/391], train loss: 0.122 | train acc: 96.234% | lr: 0.001000
   == step: [300/391], train loss: 0.126 | train acc: 96.065% | lr: 0.001000
